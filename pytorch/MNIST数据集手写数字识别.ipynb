{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b70da3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.9.0'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5885caf",
   "metadata": {},
   "source": [
    "### 数据集介绍\n",
    "MNIST包含6万张28 * 28的训练样本，1万张测试样本；\n",
    "\n",
    "这里从头搭建一个卷积神经网络，使识别准确率高达99%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "a0986ab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "BATCH_SIZE = 512 \n",
    "# 训练批次\n",
    "EPOCHS = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50004e72",
   "metadata": {},
   "source": [
    "pytorch环境中包含MNIST的数据集，直接使用即可。第一次执行会生成data_mnist文件夹，需要一些时间下载，如果下载过了，就不需要再次下载了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ccbfb0da",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data_mnist', train=True, download=True, \n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "47ccd4e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7) tensor(4) tensor(9) tensor(2)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# 展示图像\n",
    "def imshow(img):\n",
    "#     img = img * 0.3081 + 0.1307     # unnormalize\n",
    "#     print(img)\n",
    "    npimg = img.numpy()\n",
    "    plt.imshow(npimg)\n",
    "\n",
    "\n",
    "# 获取随机数据\n",
    "dataiter = iter(train_loader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# 展示图像\n",
    "imshow(images[0][0])\n",
    "# 显示图像标签\n",
    "print(' '.join('%5s' % labels[j] for j in range(4)))\n",
    "# images[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fd2a89cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x28a0fc31d90>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "img = images * 0.3081 + 0.1307 \n",
    "img[0][0]\n",
    "plt.imshow(img[0][0].numpy())\n",
    "# img[0][0].numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f905a303",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\admin\\anaconda3\\envs\\pytorch\\lib\\site-packages\\torchvision\\datasets\\mnist.py:498: UserWarning: The given NumPy array is not writeable, and PyTorch does not support non-writeable tensors. This means you can write to the underlying (supposedly non-writeable) NumPy array using the tensor. You may want to copy the array to protect its data or make it writeable before converting it to a tensor. This type of warning will be suppressed for the rest of this program. (Triggered internally at  ..\\torch\\csrc\\utils\\tensor_numpy.cpp:180.)\n",
      "  return torch.from_numpy(parsed.astype(m[2], copy=False)).view(*s)\n"
     ]
    }
   ],
   "source": [
    "test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST('./data_mnist', train=False, transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                           transforms.Normalize((0.1307,), (0.3081,))\n",
    "                       ])),\n",
    "        batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "121c33ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 1, 28, 28])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataiter = iter(test_loader)\n",
    "images, labels = dataiter.next()\n",
    "images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d6a95e6",
   "metadata": {},
   "source": [
    "定义一个网络，包含两个卷积层，conv1和cinv2，紧接着两个线性层作为输出，最后输出10个维度作为0-9的标识来确定识别出的是哪个数字。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c0388d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # 输入数据为batch*1*28*28 黑白图像 分辨率为28*28\n",
    "        # nn.Conv2d三个参数分别指 输入通道数 输出通道数 卷积核大小\n",
    "        self.conv1 = nn.Conv2d(1, 10, 5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, 3)\n",
    "        # 全连接层Linear的两个参数分别指 输入通道数 输出通道数\n",
    "        self.fc1 = nn.Linear(20*10*10, 500)\n",
    "        self.fc2 = nn.Linear(500, 10)\n",
    "    def forward(self, x):\n",
    "        in_size = x.size(0) # 即为batch_size的值 512\n",
    "        out = self.conv1(x) # 512*1*28*28 -> 512*10*24*24\n",
    "        out = F.relu(out) # 激活函数后 维度不变\n",
    "        out = F.max_pool2d(out, 2, 2) # 2*2的池化层后，维度减半\n",
    "        # 512*10*24*24 -> 512*10*12*12\n",
    "        out = self.conv2(out) # 512*10*12*12 -> 512*20*10*10\n",
    "        out = F.relu(out)\n",
    "        out = out.view(in_size, -1) # 512*20*10*10 -> 512*2000\n",
    "        out = self.fc1(out) # 512*2000 -> 512*500\n",
    "        out = F.relu(out)\n",
    "        out = self.fc2(out) # 512*500 -> 512*10\n",
    "        out = F.log_softmax(out, dim=1) # 计算log(softmax(x)) 转化为0-1之间\n",
    "        return out"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11677806",
   "metadata": {},
   "source": [
    "实例化一个网络\n",
    "\n",
    "优化器选择简单的adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "40ba4fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvNet()\n",
    "optimizer = optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daf4767e",
   "metadata": {},
   "source": [
    "定义一个训练的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "53d29acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, optimizer, epoch):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "#         data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%30 == 0: \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * len(data), len(train_loader.dataset),\n",
    "                100. * batch_idx / len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d518df34",
   "metadata": {},
   "source": [
    "定义一个测试的函数"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "a72e432e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            output = model(data)\n",
    "            test_loss += F.nll_loss(output, target, reduction='sum').item()\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            test_loss /= len(test_loader.dataset)\n",
    "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        test_loss, correct, len(test_loader.dataset),\n",
    "        100. * correct / len(test_loader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "797e48b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [14848/60000 (25%)]\tLoss: 0.073277\n",
      "Train Epoch: 1 [30208/60000 (50%)]\tLoss: 0.109212\n",
      "Train Epoch: 1 [45568/60000 (75%)]\tLoss: 0.079269\n",
      "\n",
      "Test set: Average loss: 0.0022, Accuracy: 9819/10000 (98%)\n",
      "\n",
      "Train Epoch: 2 [14848/60000 (25%)]\tLoss: 0.054845\n",
      "Train Epoch: 2 [30208/60000 (50%)]\tLoss: 0.067020\n",
      "Train Epoch: 2 [45568/60000 (75%)]\tLoss: 0.074126\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 9856/10000 (99%)\n",
      "\n",
      "Train Epoch: 3 [14848/60000 (25%)]\tLoss: 0.043873\n",
      "Train Epoch: 3 [30208/60000 (50%)]\tLoss: 0.039775\n",
      "Train Epoch: 3 [45568/60000 (75%)]\tLoss: 0.032151\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9886/10000 (99%)\n",
      "\n",
      "Train Epoch: 4 [14848/60000 (25%)]\tLoss: 0.035329\n",
      "Train Epoch: 4 [30208/60000 (50%)]\tLoss: 0.041777\n",
      "Train Epoch: 4 [45568/60000 (75%)]\tLoss: 0.029396\n",
      "\n",
      "Test set: Average loss: 0.0013, Accuracy: 9889/10000 (99%)\n",
      "\n",
      "Train Epoch: 5 [14848/60000 (25%)]\tLoss: 0.014097\n",
      "Train Epoch: 5 [30208/60000 (50%)]\tLoss: 0.032836\n",
      "Train Epoch: 5 [45568/60000 (75%)]\tLoss: 0.039692\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 9880/10000 (99%)\n",
      "\n",
      "Train Epoch: 6 [14848/60000 (25%)]\tLoss: 0.020459\n",
      "Train Epoch: 6 [30208/60000 (50%)]\tLoss: 0.019199\n",
      "Train Epoch: 6 [45568/60000 (75%)]\tLoss: 0.022571\n",
      "\n",
      "Test set: Average loss: 0.0008, Accuracy: 9878/10000 (99%)\n",
      "\n",
      "Train Epoch: 7 [14848/60000 (25%)]\tLoss: 0.006802\n",
      "Train Epoch: 7 [30208/60000 (50%)]\tLoss: 0.014399\n",
      "Train Epoch: 7 [45568/60000 (75%)]\tLoss: 0.014009\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 9902/10000 (99%)\n",
      "\n",
      "Train Epoch: 8 [14848/60000 (25%)]\tLoss: 0.003871\n",
      "Train Epoch: 8 [30208/60000 (50%)]\tLoss: 0.007118\n",
      "Train Epoch: 8 [45568/60000 (75%)]\tLoss: 0.005752\n",
      "\n",
      "Test set: Average loss: 0.0011, Accuracy: 9891/10000 (99%)\n",
      "\n",
      "Train Epoch: 9 [14848/60000 (25%)]\tLoss: 0.004366\n",
      "Train Epoch: 9 [30208/60000 (50%)]\tLoss: 0.018867\n",
      "Train Epoch: 9 [45568/60000 (75%)]\tLoss: 0.014170\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9895/10000 (99%)\n",
      "\n",
      "Train Epoch: 10 [14848/60000 (25%)]\tLoss: 0.001653\n",
      "Train Epoch: 10 [30208/60000 (50%)]\tLoss: 0.004233\n",
      "Train Epoch: 10 [45568/60000 (75%)]\tLoss: 0.004057\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9890/10000 (99%)\n",
      "\n",
      "Train Epoch: 11 [14848/60000 (25%)]\tLoss: 0.004480\n",
      "Train Epoch: 11 [30208/60000 (50%)]\tLoss: 0.002614\n",
      "Train Epoch: 11 [45568/60000 (75%)]\tLoss: 0.003154\n",
      "\n",
      "Test set: Average loss: 0.0012, Accuracy: 9916/10000 (99%)\n",
      "\n",
      "Train Epoch: 12 [14848/60000 (25%)]\tLoss: 0.003575\n",
      "Train Epoch: 12 [30208/60000 (50%)]\tLoss: 0.000647\n",
      "Train Epoch: 12 [45568/60000 (75%)]\tLoss: 0.001970\n",
      "\n",
      "Test set: Average loss: 0.0007, Accuracy: 9893/10000 (99%)\n",
      "\n",
      "Train Epoch: 13 [14848/60000 (25%)]\tLoss: 0.001135\n",
      "Train Epoch: 13 [30208/60000 (50%)]\tLoss: 0.001854\n",
      "Train Epoch: 13 [45568/60000 (75%)]\tLoss: 0.000900\n",
      "\n",
      "Test set: Average loss: 0.0015, Accuracy: 9904/10000 (99%)\n",
      "\n",
      "Train Epoch: 14 [14848/60000 (25%)]\tLoss: 0.002817\n",
      "Train Epoch: 14 [30208/60000 (50%)]\tLoss: 0.000884\n",
      "Train Epoch: 14 [45568/60000 (75%)]\tLoss: 0.002560\n",
      "\n",
      "Test set: Average loss: 0.0010, Accuracy: 9899/10000 (99%)\n",
      "\n",
      "Train Epoch: 15 [14848/60000 (25%)]\tLoss: 0.014739\n",
      "Train Epoch: 15 [30208/60000 (50%)]\tLoss: 0.004699\n",
      "Train Epoch: 15 [45568/60000 (75%)]\tLoss: 0.002727\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9897/10000 (99%)\n",
      "\n",
      "Train Epoch: 16 [14848/60000 (25%)]\tLoss: 0.002625\n",
      "Train Epoch: 16 [30208/60000 (50%)]\tLoss: 0.016712\n",
      "Train Epoch: 16 [45568/60000 (75%)]\tLoss: 0.004565\n",
      "\n",
      "Test set: Average loss: 0.0005, Accuracy: 9916/10000 (99%)\n",
      "\n",
      "Train Epoch: 17 [14848/60000 (25%)]\tLoss: 0.002840\n",
      "Train Epoch: 17 [30208/60000 (50%)]\tLoss: 0.002006\n",
      "Train Epoch: 17 [45568/60000 (75%)]\tLoss: 0.000547\n",
      "\n",
      "Test set: Average loss: 0.0006, Accuracy: 9886/10000 (99%)\n",
      "\n",
      "Train Epoch: 18 [14848/60000 (25%)]\tLoss: 0.001672\n",
      "Train Epoch: 18 [30208/60000 (50%)]\tLoss: 0.001546\n",
      "Train Epoch: 18 [45568/60000 (75%)]\tLoss: 0.008616\n",
      "\n",
      "Test set: Average loss: 0.0001, Accuracy: 9915/10000 (99%)\n",
      "\n",
      "Train Epoch: 19 [14848/60000 (25%)]\tLoss: 0.002016\n",
      "Train Epoch: 19 [30208/60000 (50%)]\tLoss: 0.002202\n",
      "Train Epoch: 19 [45568/60000 (75%)]\tLoss: 0.001964\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 9910/10000 (99%)\n",
      "\n",
      "Train Epoch: 20 [14848/60000 (25%)]\tLoss: 0.001241\n",
      "Train Epoch: 20 [30208/60000 (50%)]\tLoss: 0.001289\n",
      "Train Epoch: 20 [45568/60000 (75%)]\tLoss: 0.000515\n",
      "\n",
      "Test set: Average loss: 0.0004, Accuracy: 9906/10000 (99%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 识别准确率达到99%\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train(model, train_loader, optimizer, epoch)\n",
    "    test(model, test_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8acd7315",
   "metadata": {},
   "source": [
    "### !!!专用于kaggle 手写数字识别\n",
    "\n",
    "https://www.kaggle.com/c/digit-recognizer/leaderboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71f5a768",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1bfa249e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('digit-recognizer/train.csv')\n",
    "test = pd.read_csv('digit-recognizer/test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9c94af6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fd6791b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = train.iloc[:,1:].values.astype('float32')\n",
    "train_data = train_data.reshape((42000, 1, 28, 28))\n",
    "train_label = train.iloc[:,0].values\n",
    "test_data = test.values.astype('float32')\n",
    "test_data = test_data.reshape((28000, 1, 28, 28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "516ac308",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(42000, 1, 28, 28)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d42243f9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512,)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_label[range(512, 512*2)].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "7880d190",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_kaggle(model, train_data, train_label, optimizer, epoch):\n",
    "    model.train()\n",
    "    batch_idx = 0\n",
    "    for batch_idx in range(int(train_data.shape[0] / 512) + 1):\n",
    "        rng = range(512 * batch_idx, min(512 * (1 + batch_idx), train_data.shape[0]))\n",
    "        data = torch.from_numpy(train_data[rng,:])\n",
    "        target = torch.from_numpy(train_label[rng])\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = F.nll_loss(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        if(batch_idx+1)%30 == 0: \n",
    "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "                epoch, batch_idx * 512, train_data.shape[0],\n",
    "                100. * batch_idx * 512 / train_data.shape[0], loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "29b3ff9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [14848/42000 (35%)]\tLoss: 0.448159\n",
      "Train Epoch: 1 [30208/42000 (72%)]\tLoss: 0.151251\n",
      "Train Epoch: 2 [14848/42000 (35%)]\tLoss: 0.075001\n",
      "Train Epoch: 2 [30208/42000 (72%)]\tLoss: 0.054508\n",
      "Train Epoch: 3 [14848/42000 (35%)]\tLoss: 0.042718\n",
      "Train Epoch: 3 [30208/42000 (72%)]\tLoss: 0.027804\n",
      "Train Epoch: 4 [14848/42000 (35%)]\tLoss: 0.018764\n",
      "Train Epoch: 4 [30208/42000 (72%)]\tLoss: 0.012655\n",
      "Train Epoch: 5 [14848/42000 (35%)]\tLoss: 0.014359\n",
      "Train Epoch: 5 [30208/42000 (72%)]\tLoss: 0.010205\n",
      "Train Epoch: 6 [14848/42000 (35%)]\tLoss: 0.006431\n",
      "Train Epoch: 6 [30208/42000 (72%)]\tLoss: 0.004252\n",
      "Train Epoch: 7 [14848/42000 (35%)]\tLoss: 0.011322\n",
      "Train Epoch: 7 [30208/42000 (72%)]\tLoss: 0.009135\n",
      "Train Epoch: 8 [14848/42000 (35%)]\tLoss: 0.001984\n",
      "Train Epoch: 8 [30208/42000 (72%)]\tLoss: 0.002506\n",
      "Train Epoch: 9 [14848/42000 (35%)]\tLoss: 0.008253\n",
      "Train Epoch: 9 [30208/42000 (72%)]\tLoss: 0.001359\n",
      "Train Epoch: 10 [14848/42000 (35%)]\tLoss: 0.000761\n",
      "Train Epoch: 10 [30208/42000 (72%)]\tLoss: 0.001158\n",
      "Train Epoch: 11 [14848/42000 (35%)]\tLoss: 0.000717\n",
      "Train Epoch: 11 [30208/42000 (72%)]\tLoss: 0.000222\n",
      "Train Epoch: 12 [14848/42000 (35%)]\tLoss: 0.005439\n",
      "Train Epoch: 12 [30208/42000 (72%)]\tLoss: 0.001629\n",
      "Train Epoch: 13 [14848/42000 (35%)]\tLoss: 0.000174\n",
      "Train Epoch: 13 [30208/42000 (72%)]\tLoss: 0.000304\n",
      "Train Epoch: 14 [14848/42000 (35%)]\tLoss: 0.000125\n",
      "Train Epoch: 14 [30208/42000 (72%)]\tLoss: 0.000489\n",
      "Train Epoch: 15 [14848/42000 (35%)]\tLoss: 0.000079\n",
      "Train Epoch: 15 [30208/42000 (72%)]\tLoss: 0.000141\n",
      "Train Epoch: 16 [14848/42000 (35%)]\tLoss: 0.000077\n",
      "Train Epoch: 16 [30208/42000 (72%)]\tLoss: 0.000101\n",
      "Train Epoch: 17 [14848/42000 (35%)]\tLoss: 0.000063\n",
      "Train Epoch: 17 [30208/42000 (72%)]\tLoss: 0.000085\n",
      "Train Epoch: 18 [14848/42000 (35%)]\tLoss: 0.000054\n",
      "Train Epoch: 18 [30208/42000 (72%)]\tLoss: 0.000075\n",
      "Train Epoch: 19 [14848/42000 (35%)]\tLoss: 0.000048\n",
      "Train Epoch: 19 [30208/42000 (72%)]\tLoss: 0.000066\n",
      "Train Epoch: 20 [14848/42000 (35%)]\tLoss: 0.000042\n",
      "Train Epoch: 20 [30208/42000 (72%)]\tLoss: 0.000059\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, EPOCHS + 1):\n",
    "    train_kaggle(model, train_data, train_label, optimizer, epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "c75ab05d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_kaggle(model, test_data):\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    ans = []\n",
    "    with torch.no_grad():\n",
    "        for batch_idx in range(int(test_data.shape[0] / 512) + 1):\n",
    "            rng = range(512 * batch_idx, min(512 * (1 + batch_idx), test_data.shape[0]))\n",
    "            data = torch.from_numpy(test_data[rng,:])\n",
    "            output = model(data)\n",
    "            pred = output.max(1, keepdim=True)[1] # 找到概率最大的下标\n",
    "            pred = pred.numpy()\n",
    "            ans.append(pred.reshape((1, pred.shape[0])))\n",
    "    print('完成！')\n",
    "    return ans\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c1b2e486",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(512, 1, 28, 28)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data[range(512),:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "bac033cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "完成！\n"
     ]
    }
   ],
   "source": [
    "result = test_kaggle(model, test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "2af8490a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ans = []\n",
    "for res in result:\n",
    "    for aa in res:\n",
    "        for a in aa:\n",
    "            ans.append(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "f7710a62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28000"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "10671130",
   "metadata": {},
   "outputs": [],
   "source": [
    "commit = pd.read_csv('digit-recognizer/sample_submission.csv')\n",
    "commit['Label'] = ans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "22ebfed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "commit.to_csv('digit-recognizer/commit.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b27b7504",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
