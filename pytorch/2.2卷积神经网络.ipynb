{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d711d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ca6bb0d",
   "metadata": {},
   "source": [
    "### 卷积神经网络\n",
    "本质上是为了解决计算机视觉领域的计算问题，图像由像素点组成，若采用全连接层网络，其神经元数目即参数数量太过庞大。\n",
    "\n",
    "并且对于图像来说，其中许多特征具有重复性，因此考虑通过卷积的计算操作来提取图像的局部特征，，每一层都会计算出一些局部特征，这些局部特征再汇总到下一层，这样一层一层的传递下去，特征由小变大，最后在通过这些局部的特征对图片进行处理，这样大大提高了计算效率，也提高了准确度。\n",
    "\n",
    "#### 卷积计算\n",
    "这里使用[知乎](https://www.zhihu.com/question/39022858)上的一张图片\n",
    "![](https://pic1.zhimg.com/50/v2-7fce29335f9b43bce1b373daa40cccba_720w.webp?source=1940ef5c)\n",
    "\n",
    "#### 卷积核大小f\n",
    "#### 边界填充 padding p\n",
    "#### 步长 (s)tride\n",
    "从动图上我们能够看到，每次滑动只是滑动了一个距离，如果每次滑动两个距离呢？那就需要使用步长这个参数。\n",
    "#### 计算公式\n",
    "\n",
    "n为我们输入的矩阵的大小，$ \\frac{n-f+2p}{s} +1 $ 向下取整\n",
    "\n",
    "这个公式非常重要一定要记住\n",
    "\n",
    "### 池化层\n",
    "用于减少卷积层之间的连接，降低运算复杂度，相当于是合并，输入过滤器的大小，与卷积的操作一样，也是一步一滑动，但是过滤器覆盖的区域进行合并，只保留一个值。合并的方式也有很多种，例如我们常用的两种取最大值maxpooling，取平均值avgpooling\n",
    "\n",
    "### dropout层\n",
    "在深度学习网络的训练过程中，按照一定的概率将一部分神经网络单元暂时从网络中丢弃，相当于从原始的网络中找到一个更瘦的网络，说的通俗一点，就是随机将一部分网络的传播掐断，听起来好像不靠谱，但是通过实际测试效果非常好。\n",
    "有兴趣的可以去看一下原文[Dropout: A Simple Way to Prevent Neural Networks from Overfitting](http://jmlr.org/papers/v15/srivastava14a.html)这里就不详细介绍了。"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "905b4e88",
   "metadata": {},
   "source": [
    "### LeNet-5\n",
    "1998， Yann LeCun 的 LeNet5 [官网](http://yann.lecun.com/exdb/lenet/index.html)\n",
    "\n",
    "卷积神经网路的开山之作，麻雀虽小，但五脏俱全，卷积层、pooling层、全连接层，这些都是现代CNN网络的基本组件\n",
    "   - 用卷积提取空间特征；\n",
    "   - 由空间平均得到子样本；\n",
    "   - 用 tanh 或 sigmoid 得到非线性；\n",
    "   - 用 multi-layer neural network（MLP）作为最终分类器；\n",
    "   - 层层之间用稀疏的连接矩阵，以避免大的计算成本。\n",
    "![](lenet5.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7e4ff93d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LeNet5(\n",
      "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
      "  (fc1): Linear(in_features=400, out_features=120, bias=True)\n",
      "  (fc2): Linear(in_features=120, out_features=84, bias=True)\n",
      "  (fc3): Linear(in_features=84, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "class LeNet5(nn.Module):\n",
    "\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        # 1 input image channel, 6 output channels, 5x5 square convolution\n",
    "        # kernel\n",
    "        self.conv1 = nn.Conv2d(1, 6, 5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, 5)\n",
    "        # an affine operation: y = Wx + b\n",
    "        self.fc1 = nn.Linear(16 * 5 * 5, 120) # 这里论文上写的是conv,官方教程用了线性层\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Max pooling over a (2, 2) window\n",
    "        x = F.max_pool2d(F.relu(self.conv1(x)), (2, 2))\n",
    "        # If the size is a square you can only specify a single number\n",
    "        x = F.max_pool2d(F.relu(self.conv2(x)), 2)\n",
    "        x = x.view(-1, self.num_flat_features(x))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n",
    "\n",
    "    def num_flat_features(self, x):\n",
    "        size = x.size()[1:]  # all dimensions except the batch dimension\n",
    "        num_features = 1\n",
    "        for s in size:\n",
    "            num_features *= s\n",
    "        return num_features\n",
    "\n",
    "\n",
    "net = LeNet5()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d73343",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pytorch]",
   "language": "python",
   "name": "conda-env-pytorch-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
